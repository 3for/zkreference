\chapter{Security track}
\label{chap:track-security}

\vspace{2em}
\textbf{Original title:} ZKProof Standards Security Track Proceedings

\textbf{Date:} 1 August 2018 + subsequent revisions

{\itshape\centering
{\color{ongoingred} This document is an ongoing work in progress.}\\
{\color{ongoingred} Feedback and contributions are encouraged.}\\
}

\vspace{1em}
\textbf{Track chairs:} 
Jens Groth, Yael Kalai, Muthu Venkitasubramaniam

\textbf{Track participants:} 
Nir Bitansky, Ran Canetti, Henry Corrigan-Gibbs, Shafi Goldwasser, Charanjit Jutla, Yuval Ishai, Rafail Ostrovsky, Omer Paneth, Tal Rabin, Maryana Raykova, Ron Rothblum, Alessandra Scafuro, Eran Tromer, Douglas Wikström 



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
\label{security:intro}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{What is a zero-knowledge proof?}
\label{security:intro:what-is-a-ZK}

	A zero-knowledge proof makes it possible to prove a statement is true while preserving confidentiality of secret information.
	There are numerous uses of zero-knowledge proofs. 
\reftab{tab:basic-examples-what-is-a-ZK}\luised{Changed from ``, the table below gives a few examples'' to ``Table 1.1 gives three examples''} %, the table below gives a few examples 
gives three example\luissug{Consider saying ``example scenarios'', since the table calls it ``scenarios''} where proving claims about confidential data can be useful.
\loosen


%\begin{table}[!h]
%\caption{Basic example scenarios for ZK proofs}
\begin{center}
\def\tempTabTitle{Basic example scenarios for ZK proofs}
\mytabcap{\tempTabTitle}{\tempTabTitle\luised{Introduced table caption and table number in this and in all other tables. In the first cell, introduced the qualifier "elements" to differentiate from "scenarios"}~~~\luissug{To enable adding new examples, consider transposing the table (i.e., one example scenario per row).}}
\label{tab:basic-examples-what-is-a-ZK}

\begin{edtable}{tabular}{|l||l||l||l|}   %\begin{tabular}{|l||l|l|l|}
\hline \rowcolor{colorRowHead}\diagbox{\small \bfseries \makebox[3em]{\hspace{1em}Elements}}{\small \bfseries \makebox[0pt]{\hspace*{-3.5em}Scenarios}}
		& \bfseries \subtab[l]{1. Legal age\\\hphantom{1. }for purchase}
		& \bfseries \subtab[l]{2. Hedge fund solvency} 
		& \bfseries \subtab[l]{3. Asset transfer} \\
\hline
\hline \bfseries Statement
		& I am an adult 
		& We are not bankrupt 
		& \subtab[l]{I own this asset}\\
\hline \bfseries \subtab[l]{Confidential\\information}
		& \subtab[l]{Exact age and\\personal data} 
		& Composition of portfolio 
		& Past transactions\\
%%%\hline \bfseries \subtab[l]{Supporting\\instance}
%%%		& \subtab[l]{Driver's license\\smartcard chip} 
%%%		& Encrypted bank records
%%%		& Blockchain block\\
\hline 
\end{edtable}\vspace{1em}
\end{center}

A zero-knowledge proof system is a specification of how a prover and verifier 
can interact for the prover to convince the verifier that the statement is true.
\luissug{Comment and suggestion.\textCR
    Contrary to the chess example in section 2.4, where there is no commitment as a starting point,
for each of the three examples in Table 1.1 there must be some substract (an ``instance'') 
to support the statement with respect to the confidential info.
	\textCR\textCR
	Without the ``instance'', a ZK proof in these cases seems like magic: 
how can I prove that the license place of my car starts with the letter ``C'' 
if there is no corresponding substract (e.g., a picture of the car, or a 
car-registration record? (do you even known whether or not I have a car?).
	\textCR\textCR
	Suggestion: Consider providing some intuition about the need for a supporting ``instance''.
Depending on where the intuition is added, a corresponding row ``Supporting instance'' could 
possibly be added to \reftab{tab:basic-examples-what-is-a-ZK}, e.g., with values 
``Driver's license smartcard chip''; ``Encrypted bank records''; ``Blockchain block''. 
	\textCR\textCR
	More generally, a reflection about how to position this may come from considering how to distinguish ZKPs of membership from ZKPoKs.
	\textCR\textCR
	Might the chessboard example (described in \refsec{apps:gadgets-within-predicates}) be
interesting to put in this table? It implicitly contains the supporting instance --- everything 
is about the chessboard and chess rules that the verifier already known.}
    The proof system must be complete, sound and zero-knowledge.
\begin{itemize}
\item \textbf{Complete:} If the statement is true and both prover and verifier follow the protocol; the verifier will accept.
\item \textbf{Sound:} If the statement is false, and the verifier follows the protocol; the verifier will not be convinced.
\item \textbf{Zero-knowledge:} If the statement is true and the prover follows the protocol; the verifier will not learn any confidential information from the interaction with the prover but the fact the statement is true.
\end{itemize}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection[Requirements for a ZK proof system specification]{Requirements for a zero-knowledge proof system specification}
\label{security:intro:requirements-ZK}

A full proof system specification MUST include:
\begin{enumerate}
\item Precise specification of the type of statements the proof system is designed to handle
\item Construction including algorithms used by the prover and verifier
\item If applicable, description of setup the prover and verifier use
\item Precise definitions of security the proof system is intended to provide
\item A security analysis that proves the zero-knowledge proof system satisfies the security definitions and a full list of any unproven assumptions that underpin security
\end{enumerate}

Efficiency claims about a zero-knowledge proof system should include all relevant performance parameters for the intended usage.
Efficiency claims must be reported fairly and accurately, and if a comparison is made to other zero-knowledge proof systems a best effort must be made to compare apples to apples.

The remainder of the document will outline common approaches to specifying 
a %LB
zero-knowledge proof system, outline some construction paradigms, and give guidelines for how to present efficiency claims.
\loosen


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Terminology}
\label{security:terminology}


\luissug{Consider defining upfront the symbols for prover (\prov) and verifier (\veri), 
since the symbols will often be used as subscripts and/or as abbreviated forms.
\textCR\textCR
For example: ``A zero-knowledge proof exists in a context of two parties with different roles --- 
the prover produces the proof; the verifier verifies the proof.
Notation: \prov{} (prover); \veri{} (verifier).
Some generalizations consider the existence of several verifiers.''}
%%%%%
%%%%%
{\bfseries \hypertarget{def:instance}{Instance}:} Public input\luissug{Change ``public input'' to ``common input''.
Rationale: ZK proofs make sense even in a context private to prover-and-verifier, where the input made available to the verifier is not supposed to be disclosed publicly, e.g., to avoid linkability in a broader context;
while the use of ``public'' may be usual (e.g., present when mentioning ``private|public'' key systems, 
where ``private'' means ``secret'', and where ``public'' may mean ``private but shareable''), 
a more cautious use (e.g., ``common'') can be more informative about the actual requirement --- 
that it be known by both prover and verifier.
} 
that is known to both prover and verifier.
%LB: Consider changing to ``Scientific articles sometimes'' or ``Certain scientific articles use'' or ``Some works use''
Sometimes scientific articles use “instance” and “statement” interchangeably, but we %will 
distinguish between the two. 
Notation: $x$.
\loosen
 
{\bfseries  \hypertarget{def:witness}{Witness}:} 
Private input to the prover. Others may or may not know something about the witness. 
Notation: $w$.
 
{\bfseries \hypertarget{def:relation}{Relation}:}\luissug{Consider organizing the set of definitions in two or three classes: 
\textCR: a) participants (prover and verifier);
\textCR: b) elements instantiated in each proof execution (instance, witness, statement, setup);
\textCR: c) elements defining a proof system (language, relation) that define the proof system;} 
	Specification of relationship between instances and witness.
	A relation can be viewed as a set of permissible pairs (instance, witness). 
Notation: $R$.
 
{\bfseries \hypertarget{def:language}{Language}:} 
Set of instances that appear as a permissible pair in $R$. 
Notation: $L$.
 
{\bfseries \hypertarget{def:statement}{Statement}:} 
Defined by instance and relation. Claims the instance has a witness in the relation (which is either true or false). 
Notation: $x \in L$.

{\bfseries Security parameter:} 
Positive integer indicating the desired security level (e.g. 128 or 256) where higher security parameter means greater security.
In most constructions, distinction is made between computational security parameter and statistical security parameter. 
Notation: $k$ (computational) or $s$ (statistical).
 
{\bfseries  \hypertarget{def:setup}{Setup}:} Input to e.g. prover and verifier\luissug{Include ``CRS'' as a sub-item of the ``setup''; differentiate private setup from common setup; make a concrete definition, rather than one based on example "e.g.";\textCR\textCR
Concrete suggestion: "Setup: The inputs given to the prover and to the verifier, independent from the instance x and the witness w. The setup of each party can be decomposed into a private component (``\privsetP'' or ``\privsetV'', respectively not known to the other party) and a common component ``CommonSetup = CRS'' (known by both parties). Notation: \setP\ = (\privsetP, CRS) and : \setV\ = (\privsetV, CRS), where CRS denotes a ``\textbf{common reference string}'' (required by some zero-knowledge proof systems)."
\textCR\textCR
Another option could be to define the common setup to include x, and the private setup of P to include w, but that does not seem to be the notation option used in the subsequent sections.
}

{\bfseries Common reference string:} Some zero-knowledge systems require common public input, e.g., CRS = \setP\ = \setV.\luissug{Comment and suggestion: As is, the text may convey (there is an ``e.g.'' but it's easy to miss it) 
	that the existence of a CRS implies that the full setup of \prov\ is equal to the full setup of \veri.
	Suggestion --- explicitly define CRS as the CommonSetup component of the setup, regardless of whether or not there is a PrivateSetup components. Then if useful provide two examples, one where a CRS is enough; another where there is for example a PKI with secret keys.
	\textCR The text, using ``common public'', also seems to convey that the CRS must be public.
	Suggestion: remove "public" and require only the ``common'' aspect.
	FOr example, being public vs. common-but-not-public may make the difference between a ZK proof being transferable or not.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Specifying Statements for ZK}
\label{security:spec-statements-ZK}

 
	This document considers types of statements defined by a relation $R$ between instances $x$ and witnesses $w$.
	The relation $R$ specifies which pairs $(x,w)$ are considered related to each other, and which are not related to each other.
	The relation defines a matching language $L$ consisting of instances $x$ that have a witness $w$ in $R$.
	A statement is a claim $x \in L$, which can be true or false.
 
	The relation $R$ can for instance be specified as a program (e.g. in C or Java), which given inputs $x$ and $w$ decides to accept, meaning $(x,w) \in R$, or reject, meaning $w$ is not a witness to $x \in L$. 
	Examples of such specifications of the relation are detailed in the \hyperref[chap:track-apps]{Applications track}.
	In the academic literature, relations are often specified either as 
random access memory\luised{Introduced the extended expression of the acronym} (RAM)
programs or through %boolean 
Boolean
and arithmetic circuits, which we describe below.


\textbf{Circuits:} A circuit is a directed acyclic graph (DAG) comprised of nodes and labels for nodes, which satisfy the following constraints:
\begin{itemize}
\item Nodes with in-degree 0 are referred to as the \textbf{input nodes}\luissug{Consider adjusting all items to become of the form \textbf{<new term>}: <description>.} and are labeled with some constant (e.g., $0, 1, \ldots$) or with input variable names (e.g., $v_1, v_2, \ldots$)
\item There is a single node with out-degree 0 that is referred to as the \textbf{output node}.
\item Internal nodes\luised{``will be'' --> ``are'', consistent with the text in the first bullet} %will be 
are 
referred to as \textbf{gate nodes} and %will 
describe a computation %to be 
performed at the node.\loosen
\end{itemize}


%%%LB: Consider moving the `parametes' up, because it defines n_x and n_w, which are used in the subsequent bullets
\underline{Parameters.} Depending on the application, various parameters may be important, for instance the number of gates in the circuit, the number of instance variables $n_x$, the number of witness variables $n_w$, the circuit depth, or the circuit width.
 
\underline{Boolean Circuit satisfiability.} 
	The relation $R$ has instances of the form $x = (C, v_1, \ldots, v_{n_x})$ and witnesses $w = (w_1,...,w_{n_w})$. 
	For $(x,w)$ to be in the relation, $C$ must be a circuit with fan-in 2 gate nodes 
that are labeled with Boolean operations, e.g., \XOR\ or \AND, $v_1,...,v_{n_x}$ must specify 
truth values for some of the input nodes, and $w_1,...,w_{n_w}$ must specify 
truth values for the remaining input variables, such that when evaluating the circuit the output node becomes 1 (true).
 
\underline{Arithmetic Circuit satisfiability.} 
	The relation has instances of the form $x = (F, C, v_1,...,v_{n_x})$ and witnesses $w = (w_1,...,w_{n_w})$.
	For $(x,w)$ to be in the relation, $F$ must be a finite field (e.g., integers modulo a prime $p$), $C$ must be a circuit with gate nodes that are labeled with field operations, i.e., addition or multiplication, $v_1,...,v_{n_x}$ must specify field elements for some of the input nodes, and $w_1,...,w_{n_w}$ must specify field elements for the remaining input variables, such that when evaluating the circuit the output node becomes 1.
 

 
\textbf{Special purpose relations:} Circuit satisfiability is 
a complete problem within the non-deterministic polynomial\luised{introduced the extended form of NP} (NP) class,
i.e., it it NP-complete,
but a relation does not have to be that. 
	Examples of statements that appear in cryptographic usage include that a committed value falls in a certain range $[A;B]$ or belongs to a set $S$, that a ciphertext has plaintext 0 or that two ciphertexts encrypt the same value, that the prover has a secret key associated with a set of public verification keys for a signature scheme, etc.
 
\textbf{Setup-dependent relations:} 
Sometimes it is convenient to let the relation $R$ take an additional input setup$_R$, i.e., let the relation contain triples $(\textmd{setup}_R, x, w)$. 
	The input setup$_R$ can be used to specify persistent information, e.g., 
for arithmetic circuit satisfiability maybe the same finite field and circuit is used many times, 
so we let $\textmd{setup}_R = (F, C)$ and $x = (v_1,...,v_{n_x})$.
	The input setup$_R$ can also be used to capture trusted input the relation does not check, 
e.g., a trusted Rivest--Shamir--Adleman\luised{Introduced the extended form of the acronym.} (RSA)
modulus.
 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Syntax}
\label{security:syntax}
 
A proof system (for a relation $R$ defining a language $L$) is a protocol between a prover and a verifier sending messages to each other. 
The prover and verifier are defined by two algorithms, which we call Prove and Verify. 
The algorithms Prove and Verify may be probabilistic and may keep internal state between invocations.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection[Prove]{\textbf{Prove}$(state, m) \rightarrow (state, p)$}

The Prove algorithm in a given state receiving message $m$, updates its state and returns a message $p$.\loosen

\begin{itemize}
\item The initial state of Prove must include an instance $x$ and a witness $w$. 
	The initial state may also include additional setup information setup$_P$, e.g., $state = (setup_P, x, w)$.
\item If receiving a special initialization message $m = \tt start$ when first invoked it means the prover is to initiate the protocol.
\item If Prove outputs a special error symbol $p = \tt error$, it must output {\tt error} on all subsequent calls as well.
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection[Verify]{\textbf{Verify}$(state, p)$ $\rightarrow (state, m)$}

The Verify algorithm in a given state receiving message $p$, updates its state and returns a message $m$.\loosen

\begin{itemize}
\item The initial state of Verify must include an instance $x$.
\item The initial state of Verify may also include additional setup information setup$_V$, e.g., $state = (setup_V,x)$.
\item If receiving a special initialization message $p = \tt start$, it means the verifier is to initiate the protocol.
\item If Verify outputs a special symbol $m = \tt accept$, it means the verifier accepts the proof of the statement $x \in L$. 
			In this case, Verify must return $m = \tt accept$ on all future calls.
\item If Verify outputs a special symbol $m = \tt reject$, it means the verifier rejects the proof of the statement $x \in L$. 
			In this case, Verify must return $m = \tt reject$ on all future calls.
\end{itemize}
 
	The setup information setup$_P$ and setup$_V$ can take many forms. 
	A common example found in the cryptographic literature is that setup$_P$ = setup$_V = k$, 
where $k$ is a security parameter indicating the desired security level of the proof system. 
	It is also conceivable that setup$_P$ and setup$_V$ contain descriptions of particular choices of primitives to instantiate the proof system with, e.g., to use the SHA-256 hash function or to use a particular elliptic curve. 
	The setup information may also be generated by a probabilistic process, e.g., 
it may be that setup$_P$ and setup$_V$ include a common reference string, 
or in the case of designated verifier proofs that setup$_P$ and setup$_V$ are correlated in a particular way. 
	When we want to specifically refer to this process, we use a probabilistic setup algorithm \textbf{Setup}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection[Setup]{\textbf{Setup}(parameters)\luissug{Consider using \emph{params} (in math mode) as the 
variable containing the ``parameters'', and using \emph{aux} (in math mode) instead of ``auxiliary output''. 
Notice that \emph{aux} is anyway used from \refsec{sec:security:defs-props:completeness} onward.} 
$\rightarrow$ (\setR, \setP, \setV, auxiliary output)}

The setup algorithm may take input parameters, which could for instance be computational or statistical security parameters indicating the desired security level of the proof system, or size parameters specifying the size of the statements the proof system should work for, or choices of cryptographic primitives e.g. the SHA-256 hash function or an elliptic curve.

\begin{itemize}
\item The setup algorithm returns an input \setR\ for the relation the proof system is for. An important special case is where the \setR\ is just the empty string, i.e., the relation is independent of any setup.
\item The setup algorithm returns \setP\ for the prover and \setV\ for the verifier.
\item There may potentially be additional auxiliary outputs.
\item If the inputs are malformed or any error occurs, the Setup algorithm may output an error symbol.
\end{itemize}


Some examples of possible setups.
\begin{itemize}

\item NIZK proof system for 3SAT in the uniform reference string model based on trapdoor permutations
		\begin{itemize}
		\item $\setR = n$, where $n$ specifies the maximal number of clauses
		\item $\setP = \setV$ = uniform random string of length $N = size(n,k)$ for some function $size(n,k)$ of $n$ and security parameter $k$
		\end{itemize}

\item Groth-Sahai proofs for pairing-product equations
	\begin{itemize}
	\item $\setR$ = description of bilinear group defining the language
	\item $\setP = \setV$ = common reference string including description of the bilinear group in \setR\ plus additional group elements
	\end{itemize}

\item SNARK for QAP such as e.g. Pinocchio
	\begin{itemize}
	\item \setR\ = QAP specification including finite field F and polynomials
	\item $\setP = \setV$ = common reference string including a bilinear group defined over the same finite field and some group elements

The prover and verifier do not use the same group elements in the common reference string. For efficiency reasons, one may let \setP\ be the subset of the group elements the prover uses, and \setV\ another (much smaller) subset of group elements the verifier uses.\loosen
	\end{itemize}

\item Cramer-Shoup hash proof systems
	\begin{itemize}
	\item \setR\ = specifies finite cyclic group of prime order
	\item \setP\ = the cyclic group and some group elements
	\item \setV\ = the cyclic group and some discrete logarithms
	\end{itemize}

\end{itemize}


It depends on the concrete setting how Setup runs. 
In some cases, a trusted third party runs an algorithm to generate the setup. 
In other cases, Setup may be a multi-party computation offering resilience against a subset of corrupt and dishonest parties (and the auxiliary output may represent side-information the adversarial parties learn from the MPC protocol). 
Yet, another possibility is to work in the plain model, where the setup does nothing but copy a security parameter, e.g., $\setP = \setV = k$.
 
There are variations of proof systems, e.g., multi-prover proof systems and commit-and-prove systems; this document only covers standard systems.
 
\textbf{Common reference string:} If the setup information is public and known to everybody, we say the proof system is in the common reference string model. 
The setup may for instance specify $\setR = \setP = \setV$, which we then refer to as a common reference string CRS.
 
\textbf{Non-interactive proof systems:} 
A proof system is non-interactive if the interaction consists of a single message from the prover to the verifier.
After receiving the prover’s message $p$\luiscom{Should it be \textbackslash pi?} (called a proof), the verifier then returns accept or reject.
 
\textbf{Public verifiability vs designated verifier:} 
If \setV\ is public information (e.g. in the CRS model) known to multiple parties in a non-interactive proof system, then they can all verify a proof $p$. 
In this case, the proof is transferable, the prover only needs to create it once after which it can be copied and transferred to many verifiers. 
If on the other hand, \setV\ is private we refer to it as a designated verifier proof system.
 
\textbf{Public coin:} 
In an interactive proof system, we say it is public coin if the verifier’s messages are uniformly random and independent of the prover’s messages.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Definition and Properties}
\label{security:defs-props}
 
A proof system (Setup, Prove, Verify) for a relation R must be complete and sound.
It may have additional desirable security properties such as being a proof of knowledge or being zero knowledge.\loosen
 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Completeness}
\label{sec:security:defs-props:completeness}

Intuitively, a proof system is complete if an honest prover with a valid witness $w$ for a statement $x \in L$ can convince an honest verifier that the statement is true. 
A full specification of a proof system \textbf{must} include a precise definition of completeness that captures this intuition. 
We give an example of a definition below for a proof system where the prover initiates.
 
Consider a completeness attacker \textbf{Adversary} in the following experiment.

\begin{enumerate}
    \item Run \textbf{Setup}(\params) $\rightarrow (\setR, \setP, \setV, aux)$
    \item Let the adversary choose a worst case instance and witness:\\
					\textbf{Adversary}$(\params, \setR, \setP, \setV, aux) \rightarrow (x,w)$
    \item Run the interaction between Prove and Verify until the prover returns {\tt error} or the verifier accepts or rejects. 
		Let $result$ be the outcome, with the convention that $result = \tt error$ if the protocol does not terminate.
		\brkttext{\textbf{Prove}$(\setP, x, w, \tt start)$ ; \textbf{Verify}$(\setV, x)$} $\rightarrow result$
\end{enumerate}


\begin{bulletize}
    \item \textbf{Adversary} wins if $(\setR, x, w) \in R$ and result is not {\tt accept}.
\end{bulletize}
 
We define the adversary’s advantage as a function of parameters to be
              	Advantage(\params) = Pr[\textbf{Adversary} wins]
 
A proof system for $R$ running on parameters is complete if nobody ever constructs an efficient adversary with significant advantage.
 
It depends on the application what is an efficient adversary (computing equipment, running time, memory consumption, usage lifetime, incentives, etc.) and how large an advantage can be tolerated. 
Special strong cases include statistical completeness (aka unconditional completeness) where the winning probability is small for any adversary, and perfect completeness, where for any adversary the advantage is exactly 0.
 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Soundness}
\label{sec:security:defs-props:soundness}

Intuitively, a proof system is sound if a cheating prover has little or no chance of convincing an honest verifier that a false statement is true. 
A full specification of a proof system must include a precise definition of soundness that captures this intuition. 
We give an example of a definition below.
\loosen
 
Consider a soundness attacker \textbf{Adversary} in the following experiment.

\begin{enumerate}
    \item Run \textbf{Setup}(\params) $\rightarrow (\setR, \setP, \setV, aux)$
    \item Let the (stateful) adversary choose an instance\\
					\textbf{Adversary}$(\params, \setR, \setP, \setV, aux) \rightarrow x$
    \item Let the adversary interact with the verifier and $result$ be the verifier’s output 	
					(letting $result = \tt reject$ if the protocol does not terminate).
\brkttext{\textbf{Adversary} ; \textbf{Verify}$(\setV, x)$} $\rightarrow result$
\end{enumerate}

    \begin{bulletize}
		\item \textbf{Adversary} wins if $(\setR, x) \notin L$ and result is {\tt accept}.
		\end{bulletize}
 
We define the adversary’s advantage as a function of parameters to be \newline
\hphantom{We define the } Advantage(\params) = \text{Pr}[\textbf{Adversary} wins]
 
A proof system for $R$ running on parameters is sound if nobody ever constructs an efficient adversary with significant advantage.
 
It depends on the application what is considered an efficient adversary (computing equipment, running time, memory consumption, usage lifetime, etc.) and how large an advantage can be tolerated. 
Special strong notions of soundness includes statistical soundness (aka unconditional soundness) where any adversary has small chance of winning, and perfect soundness, where for any adversary the advantage is exactly 0.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Proof of knowledge}
\label{sec:security:defs-props:proof-of-knowledge}

 Intuitively, a proof system is a proof of knowledge if it is not just sound, but that the ability to convince an honest verifier implies that the prover must “know” a witness. 
To “know” a witness can be defined as it being possible to extract a witness from a successful prover. 
If a proof system is claimed to be a proof of knowledge, then the full specification \textbf{must} include a precise definition of knowledge soundness that captures this intuition, but we do not define proofs of knowledge here.\luissug{Consider explaining better the meaning of ZKPoK, and presenting the definition / game for extractability. It's unclear why the document makes the option to not proceed with this discussion.}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Zero knowledge}
\label{sec:security:defs-props:zero-knowledge}

Intuitively, a proof system is zero knowledge if it does not leak any information about the prover’s witness beyond what the attacker may already know about the witness from other sources. Zero knowledge is defined through the specification of an efficient simulator that can generate kosher looking proofs without access to the witness. 
If a proof system is claimed to be zero knowledge, then the full specification MUST include a precise definition of zero knowledge that captures this intuition. 
We give an example of a definition below.
 
A proof system is zero knowledge if the designers provide additional efficient algorithms \textbf{SimSetup}, \textbf{SimProve} such that realistic attackers have small advantage in the game below. 
Let \textbf{Adversary} be an attacker in the following experiment:

\newcounter{cntStepZKgame}\setcounter{cntStepZKgame}{0}
\newcommand{\newStepZKgame}{\refstepcounter{cntStepZKgame}\item[\arabic{cntStepZKgame}.]}

\begin{enumerate}
    \newStepZKgame\label{step:ZKgame:rand-bit} Choose a bit uniformly at random {0,1} $\rightarrow$ b
    \newStepZKgame\label{step:ZKgame:setup-if-0} If $b = 0$ run \textbf{Setup}(\params) $\rightarrow (\setR, \setP, \setV, aux)$
    \newStepZKgame\label{step:ZKgame:setup-if-1} Else if $b = 1$ run \textbf{SimSetup}(\params) $\rightarrow (\setR, \setP, \setV, aux, trapdoor)$
    \newStepZKgame\label{step:ZKgame:adv-choose-inst-and-witn} Let the (stateful) adversary choose an instance and witness\\
					\textbf{Adversary}$(\params, \setR, \setP, \setV, aux) \rightarrow (x,w)$
    \newStepZKgame\label{step:ZKgame:not-in-R} If $(\setR, x, w) \notin R$ return $guess = 0$
    \newStepZKgame\label{step:ZKgame:interact-if-0} If $b = 0$ let the adversary interact with the prover and output a guess (letting $guess = 0$ if the protocol does not terminate).
\brkttext{\textbf{Prove}$(\setP, x, w)$ ; \textbf{Adversary}} $\rightarrow guess$
    \newStepZKgame\label{step:ZKgame:interact-if-1} Else if $b = 1$ let the adversary interact with a simulated prover and output a guess (letting $guess = 0$ if the protocol does not terminate)\\
					\brkttext{\textbf{SimProve}$(\setP, x, trapdoor)$ ; \textbf{Adversary}} $\rightarrow guess$
\end{enumerate}
 
\begin{bulletize}
    \item \textbf{Adversary} wins if $guess = b$
\end{bulletize}
 
We define the adversary’s advantage as a function of parameters to be \newline
\hphantom{We define the } Advantage(parameters) = | \text{Pr}[\textbf{Adversary} wins] - $1/2$ |
 
A proof system for $R$ running on parameters is zero knowledge if nobody ever constructs an efficient adversary with significant advantage.
 
It depends on the application what is considered an efficient adversary (computing equipment, running time, memory consumption, usage lifetime, etc.) and how large an advantage can be tolerated. 
Special strong notions include statistical zero knowledge (aka unconditional zero knowledge) where any adversary has small advantage, and perfect zero knowledge, where for any adversary the advantage is exactly 0.

\luissug{Consider adding the following remark / special case: 
``The ZK property of a proof does not depend on whether or not the verifier knows something about the witness being proven.
	However, certain proofs may be designed for the specific case where the verifier 
also knows the witness (or a valid witness), and where such knowledge enables an 
efficient production of a proof (via some interaction), and/or an efficient verification.%
	%May be interesting to provide a concrete example. To-do: check that all the notation is consistent even with this type of case.
''}


\underline{multi-theorem zero knowledge.} 
In the zero-knowledge definition, the adversary interacts with the prover or simulator on a single instance. 
It is possible to strengthen the zero-knowledge definition to guard also against an adversary that sees proofs for multiple instances.
 
\underline{Honest verifier zero knowledge.} 
	A weaker privacy notion is honest verifier zero-knowledge, where we assume the adversary follows the protocol honestly 
(i.e., in steps \ref{step:ZKgame:interact-if-0} and \ref{step:ZKgame:interact-if-1} in the definition it runs the verification algorithm). 
	It is a common design technique to first construct an HVZK proof system, and then use efficient standard transformations to get a proof system with full zero knowledge.
 
\underline{Witness indistinguishability and witness hiding.} 
Sometimes a weaker notion of privacy than zero knowledge suffices. 
Witness-indistinguishable proof systems make it infeasible for an adversary to distinguish which out of several possible witnesses the prover has. Witness-hiding proof systems ensure the interaction with an honest prover does not help the adversary to compute a witness.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Advanced security properties}
\label{sec:security:defs-props:advanced-security-properties}

The literature describes many advanced security notions a proof system may have.
These include security under concurrent composition and nonmalleability to guard against man-in-the-middle attacks, security against reset attacks in settings where the adversary has physical access, simulation soundness and simulation extractability to assist sophisticated security proofs, and universal composability.
 
\underline{Universal composability.} The UC framework defines a protocol to be secure if it realizes an ideal functionality in an arbitrary environment. We can think of an ideal zero-knowledge functionality as taking an input $(x,w)$ from the prover and if and only if $(x,w) \in R$ it sends the message$ (x, \tt accept)$ to the verifier. The ideal functionality is perfectly sound, since no statement without valid witness will be accepted, and perfectly zero knowledge, since the proof is just the message accept. A proof system is then UC secure, if the real life execution of the system is `security-equivalent’ to the execution of the ideal proof system functionality. Usually it takes more work to demonstrate a proof system is UC secure, but on the other hand the framework offers strong security guarantees when the proof system is composed with other cryptographic protocols.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Examples of setup and trust}
\label{sec:security:defs-props:examples-of-setup-and-trust}

The security definitions assume a trusted setup. There are several variations of what the setup looks like and the level of trust placed in it.

\begin{bulletize}
	\item \underline{No setup or trustless setup.}
	This is when no trust is required, for instance because the setup is just a copy of a security parameter $k$, or because everybody can verify the setup is correct directly.
    
	\item \underline{Uniform random string.}
	All parties have access to a uniform random string URS = \setR = \setP = \setV. 
	We can distinguish between the lighter trust case where the parties just need to get a uniformly sampled string, which they may for instance get from a trusted common source of randomness e.g. sunspot activity, and the stronger trust case where zero-knowledge relies on the ability to simulate the URS generation together with a simulation trapdoor.

  \item \underline{Common reference string.}
	The URS model is a special case of the CRS model. 
	But in the CRS model it is also possible that the common setup is sampled with a non-uniform distribution, which may exclude easy access to a trusted common source. 
	A distinction can be made whether the CRS has a verifiable structure, i.e., it is easy to verify it is well-formed, or whether full trust is required.
    
	\item \underline{Designated verifier setup.}
	If we have a setup that generates correlated \setP\ and \setV, where \setV\ is intended only for a designated verifier, we also need to place trust in the setup algorithm. 
	This is for instance the case in Cramer-Shoup public-key encryption where a designated verifier NIZK proof is used to provide security under chosen-ciphertext attack. 
	Here the setup is generated as part of the key generation process, and the recipient can be trusted to do this honestly because it is the recipient’s own interest to make the encryption scheme secure.
    
	\item \underline{Random oracle model.}
	The common setup describes a cryptographic hash function, e.g. SHA256. 
	In the random oracle model, the hash function is heuristically assumed to act like a random oracle that returns a random value whenever it is queried on an input not seen before. 
	There are theoretical examples where the random oracle model fails, exploiting the fact that in real life the hash function is a deterministic function, but in practice the heuristic gives good efficiency and currently no weaknesses are known for ‘natural’ proof systems.
    
	\item There are several proposals to reduce the trust in the setup such as using secure multi-party computation to generate a CRS, using a multi-string model where there are many CRSs and security only relies on a majority being honestly generated, and subversion resistant CRS where zero-knowledge holds even against a maliciously generated CRS.
\end{bulletize}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Assumptions}
\label{security:assumptions}
 
A full specification of a proof system \textbf{must} state the assumptions under which it satisfies the security definitions and demonstrate the assumptions imply the proof system has the claimed security properties.
 
A security analysis may take the form of a mathematical proof by reduction, which demonstrates that a realistic adversary gaining significant advantage against a security property, would make it possible to construct a realistic adversary gaining significant advantage against one of the underpinning assumptions.
 
To give an example, suppose soundness relies on a collision-resistant hash function. The demonstration of this fact may take the form of describing a simple and efficient algorithm \textbf{Reduction}, which may call a soundness attacker \textbf{Adversary} as a subroutine a few times. Furthermore, the demonstration may establish that the advantage \textbf{Reduction} has in finding a collision is closely related to the advantage an arbitrary \textbf{Adversary} has against soundness, for instance

Advantage\_soundness(\params) $\leq$ 8 $\times$ Advantage\_collision(\params)
 
Suppose the proof system is designed such that we can instantiate it with the SHA-256 hash function as part of the parameters.
If we assume the risk of an attacker with a budget of \$1,000,000 finding a SHA-256 collision within 5 years is less than $2^{-128}$, then the reduction shows the risk of an adversary with similar power breaking soundness is less than $2^{-125}$.
 
\textbf{Cryptographic assumptions:} Cryptographic assumptions, i.e. intractability assumptions, specify what the proof system designers believe a realistic attacker is incapable of computing.
Sometimes a security property may rely on no cryptographic assumptions at all, in which case we say security of unconditional, i.e., we may for instance say a proof system has unconditional soundness or unconditional zero knowledge. Usually, either soundness or zero knowledge is based on an intractability assumption though.
The choice of assumption depends on the risk appetite of the designers and the type of adversary they want to defend against.
 
\underline{Plausibility.} At all costs, an intractability assumption that has been broken should not be used. We recommend designing flexible and modular proof systems such that they can be easily updated if an underpinning cryptographic assumption is shown to be false. 

Sometimes, but not always, it is possible to establish an order of plausibility of assumptions. It is for instance known that if you can break the discrete logarithm problem in a particular group, then you can also break the computational Diffie-Hellman problem in the same group, but not necessarily the other way around. This means the discrete logarithm assumption is more plausible than the computational Diffie-Hellman assumption and therefore preferable from a security perspective.
 
\underline{Post-quantum resistance.} There is a chance that quantum computers will be developed within a few decades. Quantum computers are able to efficiently break some cryptographic assumptions, e.g., the discrete logarithm problem. If the expected lifetime of the proof system extends beyond the emergence of quantum computers, then it is necessary to rely on intractability assumptions that are believed to resist quantum computers.    	
Different security properties may require different lifetimes. For instance, it may be that proofs are verified immediately and hence post-quantum soundness is not required, while at the same time an attacker may collect and store proof transcripts and later try to learn something from them, so post-quantum zero knowledge is required.
 
\underline{Concrete parameters.} It is common in the cryptographic literature to use vague phrasing such as “the advantage of a polynomial time adversary is negligible” when describing the theory behind a proof system. However, concrete and precise security is needed for real-world deployment. A proof system should therefore come with concrete parameter recommendation and a statement about the level of security they are believed to provide.  
 
\textbf{System assumptions:} Besides cryptographic assumptions, a proof system may rely on assumptions about the equipment or environment it works in.
As an example, if the proof system relies on a trusted setup it should be clearly stated what kind of trust is placed in.

\textbf{Setup.} If the prover or verifier are probabilistic, they require an entropy source to generate randomness. 
Faulty pseudorandomness generation has caused vulnerabilities in other types of cryptographic systems, so a full specification of a proof system should make explicit any assumptions it makes about the nature or quality of its source of entropy.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Efficiency}
\label{security:Efficiency}
 
A specification of a proof system may include claims about efficiency and if it does the units of measurement MUST be clearly stated. Relevant metrics may include:

\begin{bulletize}
    \item \textbf{Round complexity:} Number of transmissions between prover and verifier. Usually measured in the number of moves, where a move is a message from one party to the other.
An important special case is that of 1-move proof systems, aka non-interactive proof systems, where the verifier receives a proof from the prover and directly decides whether to accept or not. Non-interactive proofs may be transferable, i.e., they can be copied, forwarded and used to convince several verifiers.
    \item \textbf{Communication:} Total size of communication between prover and verifier. Usually measured in bits.
    \item \textbf{Prover computation:} Computational effort the prover expends over the duration of the protocol. Sometimes measured as a count of the dominant cryptographic operations (to avoid system dependence) and sometimes measured in seconds on a particular system (when making concrete measurements).
    \item Depending on the intended usage, many other metrics may be important: memory consumption, energy consumption, entropy consumption, potential for parallelisation to reduce time, and offline/online computation trade-offs.
    \item \textbf{Verifier computation:} Computational effort the verifier expends over the duration of the protocol.
    \item Setup \textbf{cost:} Size of setup parameters, e.g. a common reference string, and computational cost of creating the setup.
\end{bulletize} 

Readers of a proof system specification may differ in the granularity they need in the efficiency measurements. Take as an example a proof system consisting of an information theoretic core that is then compiled with cryptographic primitives to yield the full system. An implementer will likely want to have a detailed performance analysis of the information theoretic core as well as the cryptographic compilation, since this will guide her choice of trade-offs and optimizations. A consumer on the other hand will likely want to have a high-level performance analysis and an apples-to-apples comparison to competing proof systems. We therefore recommend to provide both a detailed analysis that quantifies all the dominant efficiency costs, and a bottom-line analysis that summarizes performance for reasonable choices of parameters and identifies the optimal performance region.
\loosen


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Taxonomy of Constructions}
\label{security:taxonomy} 
 
There are many different types of zero-knowledge proof systems in the literature that offer different tradeoffs between communication cost, computational cost, and underlying cryptographic assumptions. 
Most of these proofs can be decomposed into an “information-theoretic” zero-knowledge proof system, sometimes referred to as a zero-knowledge \emph{probabilistically checkable proof} (PCP), and a \emph{cryptographic compiler}, or crypto compiler for short, that compiles such a PCP into a zero-knowledge proof.
(Here and in the following, we will sometimes omit the term “zero-knowledge” for brevity even though we focus on zero-knowledge proof systems by default.)
 
Different kinds of PCPs require different crypto compilers. 
The crypto compilers are needed because PCPs make unrealistic independence assumptions between values contributed by the prover and queries made by the verifier, and also do not take into account the cost of communicating a long proof. 
The main advantage of this separation is modularity: PCPs can be designed, analyzed and optimized independently of the crypto compilers, and their security properties (soundness and zero-knowledge) do not depend on any cryptographic assumptions. 
It may be beneficial to apply different crypto compilers to the same PCP, as different crypto compilers may have incomparable efficiency and security features (e.g., trade succinctness for better computational complexity or post-quantum security).
\loosen
 
PCPs can be divided into two broad categories: ones in which the verifier makes point queries, namely reads individual symbols from a proof string, and ones where the verifier makes linear queries that request linear combinations of field elements included in the proof string. Crypto compilers for the former types of PCPs typically only use symmetric cryptography (a collision-resistant hash function in their interactive variants and a random oracle in their non-interactive variants) whereas crypto compilers for the latter type of PCPs typically use homomorphic public-key cryptographic primitives (such as SNARK-friendly pairings).
 
\reftab{tab:different-types-of-PCP} %The following table 
summarizes different types of PCPs and corresponding crypto compilers. 
The efficiency and security features of the resulting zero-knowledge proofs depend on both the parameters of the PCP and the features of the crypto compiler.
 

\begin{table}[H]
\begin{center}
\mytabcap{Different types of PCPs}{Different types of PCPs}\label{tab:different-types-of-PCP}

\newcommand{\murii}[1]{\multirow{2}{*}{\subtabL{#1}}}
\newcommand{\muriii}[1]{\multirow{3}{*}{\subtabL{#1}}}

\begin{edtable}{tabular}{|l|c|l|l|l|}
\hline \rowcolor{colorRowHead}\textbf{Proof System} & \bfseries \subtab{Inter-\\action} & \textbf{Queries to Proof} & \textbf{Crypto Compilers}\luistodo{Replace/add entries in this column by/with corresponding citation tags using command \textbackslash cite\{...\}} & \textbf{Features} \\
\hline \murii{\hyperref[proof-system:classical-proof]{Classical proof}\\(no zk)} & No & All 
			& GMW, ..., 
			& \ref{feat:plain},\ref{feat:symm-key},\ref{subfeat:succinct:non}\\
	\cline{4-5}
			& & & Cramer-Damgård 98, ...
			& \ref{feat:plain},\ref{subfeat:succinct:non} \\
\hline \hyperref[proof-system:classical-PCP]{Classical PCP} & No & Point Queries 
			& Kilian, Micali, IMS 
			& \ref{feat:plain},\ref{feat:symm-key},\ref{subfeat:succinct:polylog} \\
\hline \hyperref[proof-system:linear-PCP]{Linear PCP} & No & Inner-product Queries 
			& \subtabL{IKO,Groth10,GGPR,BCIOP}
			& \ref{subfeat:succinct:fully} \\
\hline \murii{\hyperref[proof-system:IOP]{IOP}} & \murii{Yes} & \murii{Point Queries}
			& BCS16+ZKStarks
			& \ref{feat:plain},\ref{feat:symm-key},\ref{subfeat:succinct:polylog}\\
	\cline{4-5}
			& & & BCS16+Ligero
			& \ref{feat:plain},\ref{feat:symm-key},\ref{subfeat:succinct:sqrt}\\
\hline \muriii{\hyperref[proof-system:linear-IOP]{Linear IOP}} & \muriii{Yes} & \muriii{Inner-product\\Queries} 
			& Hyrax
			& \ref{feat:plain},\ref{subfeat:succinct:polylog}/\ref{subfeat:succinct:depth} \\
	\cline{4-5}
			& & & vSQL
			& \ref{subfeat:succinct:depth} \\
	\cline{4-5}
			& & & vRAM
			& \ref{subfeat:succinct:polylog} \\
\hline \murii{\hyperref[proof-system:ILC]{ILC}} & \murii{Yes} & \murii{Matrix-vector\\Queries}
			& \subtabL{Bootle 16,18\\} 
			& \ref{feat:plain},\ref{subfeat:succinct:polylog} \\
	\cline{4-5}
			& & & Bootle 17
			& \ref{feat:plain},\ref{feat:symm-key},\ref{subfeat:succinct:sqrt} \\
\hline 
\end{edtable}\vspace{1em}
\end{center}
\end{table}
 
\textbf{Notation:} We say that a verifier makes “point queries” to the proof $\Pi$ if the verifier has access to 
a proof oracle $O^{\Pi}$ that takes as input an index i and outputs the $i$-th symbol $\Pi(i)$ of the proof. 
	We say that a verifier makes “inner-product queries” to the proof $\Pi \in \field^m$ (for some finite field \field) if 
the proof oracle takes as input a vector $q \in \field^m$ and returns the value $\brktmath{\Pi, q} \in \field$. 
	We say that a verifier makes “matrix-vector queries” to the proof $\Pi \in \field^{m\times k}$ if the proof oracle 
takes as input a vector $q \in \field^k$ and returns the matrix-vector product $(\Pi.q) \in \field^m$.

\newcounter{cntFeat}\setcounter{cntFeat}{0}
\newcommand{\newfeat}{\refstepcounter{cntFeat}\arabic{cntFeat}}

\newcounter{cntSubFeat}[cntFeat]\setcounter{cntSubFeat}{0}
\newcommand{\newsubfeat}{\refstepcounter{cntSubFeat}\alph{cntSubFeat}}
\renewcommand{\thecntSubFeat}{\arabic{cntFeat}\alph{cntSubFeat}}


\begin{enumerate}
    \item[\newfeat.\label{feat:plain}] No trusted setup
    \item[\newfeat.\label{feat:symm-key}] Relies only on symmetric-key cryptography (e.g., collision-resistant hash functions and/or random oracles)
    \item[\newfeat.\label{feat:succint}] Succinct proofs
				\begin{enumerate}
        \item[(\newsubfeat)\label{subfeat:succinct:fully}] Fully succinct: Proof length independent of statement size. $O(1)$ crypto elements (fully)
        \item[(\newsubfeat)\label{subfeat:succinct:polylog}] Polylog succinct: Polylogarithmic number of crypto elements
        \item[(\newsubfeat)\label{subfeat:succinct:depth}] Depth-succinct: Depends on depth of a verification circuit representing the statement.
        \item[(\newsubfeat)\label{subfeat:succinct:sqrt}] Sqrt succinct: Proportional to square root of circuit size
        \item[(\newsubfeat)\label{subfeat:succinct:non}] Non succinct: Proof length is larger than circuit size.
				\end{enumerate}
\end{enumerate}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%\paragraph{i) Proof Systems}
\subsection{Proof Systems}

\emph{Note:} For all of the applications we consider, the prover must run in polynomial time, given a statement-witness pair, and the verifier must run in (possibly randomized) polynomial time.\loosen

	\begin{enumerate}[label=\alph*.]
	
	\item\pslabel{proof-system:classical-proof} \underline{Classical Proofs}: In a classical NP/MA proof, the prover sends the verifier a proof string $\pi$, the verifier reads the entire proof $\pi$ and the entire statement $x$, and accepts or rejects.
  
	\item\pslabel{proof-system:classical-PCP} \underline{PCP (Probabilistically Checkable Proofs)}: In a PCP proof, the prover sends the verifier a (possibly very long) proof string $\pi$, the verifier makes “point queries” to the proof, reads the entire statement x, and accepts or rejects. Relevant complexity measures for a PCP include the verifier’s query complexity, the proof length, and the alphabet size.
  
	\item\pslabel{proof-system:linear-PCP} \underline{Linear PCPs:} In a linear PCP proof, the prover sends the verifier a (possibly very long) proof string $\pi$, which lies in some vector space $\field^m$. 
	The verifier makes some number of linear queries to the proof, reads the entire statement $x$, and accepts or rejects. 
	Relevant complexity measures for linear PCPs include the proof length, query complexity, field size, and the complexity of the verifier’s decision predicate (when expressed as an arithmetic circuit).
  
	\item\pslabel{proof-system:IOP} \underline{IOP (Interactive Oracle Proofs)}: 
	An IOP is a generalization of a PCP to the interactive setting. 
	In each round of communication, the verifier sends a challenge string $c_i$ to the prover and the prover responds with a PCP proof $\pi_i$ that the verifier may query via point queries.
	After several rounds of interactions, the verifier accepts or rejects. 
	Relevant complexity measures for IOPs are the round complexity, query complexity, and alphabet size. 
	IOP generalizes the notion of Interactive PCP \cite{2008:icalp:interactive-PCP}, and coincides with the notion of Probabilistically Checkable Interactive Proof \cite{2016:stoc:Constant-round-Interactive-Proofs-for-Delegating-Computation}.
  
	\item\pslabel{proof-system:linear-IOP} \underline{Linear IOP}: 
	A linear IOP is a generalization of a linear PCP to the interactive setting. (See IOP above.) 
	Here the prover sends in each round a proof vector $\pi_i$ that the verifier may query via linear (inner-product) queries.
  
	\item\pslabel{proof-system:ILC} \underline{ILC (Ideal Linear Commitment)}: 
	The ILC model is similar to linear IOP, except that the prover sends in each round a proof matrix rather than proof vector, and the verifier learns the product of the proof matrix and the query vector. 
	This model relaxes the Linear Interactive Proofs (LIP) model from \cite{2013:tcc:snargs-via-LIPs}. 
	(That is, each ILC proof matrix may be the output of an arbitrary function of the input and the verifier’s messages. In contrast, each LIP proof matrix must be a linear function of the verifier’s messages.) 
	Important complexity measures for ILCs are the round complexity, query complexity, and dimensions of matrices.
	
	\end{enumerate}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\textbf{ii) Compilers: Cryptographic}
\subsection{Compilers: Cryptographic}
	
	\begin{enumerate}[label=\alph*.]
  
	%\item \underline{Cramer-Damgård:} 
	\item \underline{Cramer-Damgård \cite{1998:crypto:zkps-for-finite-field-arithmetic}:} 
	Compiles an NP proof into a zero-knowledge proof. 
	The prover evaluates the circuit $C$ recognizing the relation on its statement-witness pair $(x,w)$. 
	The prover commits to every wire value in the circuit and sends these commitments to the verifiers. 
	The prover then convinces the verifier using sigma protocols that the wire values are all consistent with each other. 
	The prover opens the input wires to $x$ and thus convinces the verifier that the circuit $C(x, .)$ is satisfied on some witness $w$. 
	The compiler uses additively homomorphic commitments (instantiated using the discrete-log assumption, for example) and generating or verifying the proof requires a number of public-key operations that is linear in the size of the circuit $C$.
   
	\item \underline{Kilian \cite{1995:crypto:Improved-Efficient-Arguments} / Micali \cite{2000:SIAM:Computationally-Sound-Proofs} / IMS \cite{2012:tcc:On-Efficient-ZK-PCPs}}: 
	Compiles a PCP with a small number of queries into a succinct proof. 
	The prover produces a PCP proof that $x$ in $L$. 
	The prover commits to the entire PCP proof using a Merkle tree. 
	The verifier asks the prover to open a few positions in the proof. 
	The prover opens these positions and uses Merkle proofs to convince the verifier that the openings are consistent with the Merkle commitment. 
	The verifier accepts iff the PCP verifier accepts. 
	The compiler can be made non-interactive in the random oracle model via the Fiat-Shamir\luiscom{add somewhere a reference to the Fiat-Shamir transformation} heuristic.
	
  \item \underline{GGPR \cite{2013:QSPs-and-succinct-NIZKs-without-PCPs} / BCIOP \cite{2013:tcc:snargs-via-LIPs}:} 
	Compiles a linear PCP into a SNARG via a transformation to LIPs. 
	The public parameters of the SNARG are as long as the linear PCP proof and the SNARG proof consists of a constant number of ciphertexts/commitments (if the linear PCP has constant query complexity). 
	In the public verification setting, this compiler relies on “SNARG-friendly” bilinear maps and is thus not post-quantum secure. 
	In the designated verifier setting, it can be made post-quantum secure via linear-only encryption \cite{2017:eurocrypt:lattice-based-snargs}. 
	Generating the proof requires a number of public-key operations that grows linearly (or quasi-linearly) in the size of the circuit recognizing the relation.
   
	\item \underline{BCS16 \cite{2016:tcc:IOPs}:} 
	A generalization of the Fiat-Shamir compiler that is useful for collapsing many-round public-coin proofs (such as IOPs) into NIZKs in the random-oracle model.

	\item \underline{Hyrax \cite{2018:SP:Doubly-efficient-zkSNARKs-without-trusted-setup} and vSQL \cite{2017:SP:vSQL}:} 
	Give mechanisms for compiling the GKR protocol \cite{2015:JACM:delegating-computation-interactive-proofs-for-muggles} into NIZKs in the random oracle model. 
	The techniques in these works generalize to compile any public-coin linear IOP (without zero knowledge) into a non-interactive zero-knowledge proof in the random-oracle model, that additionally relies on algebraic commitment schemes.
	The latter are typically implemented using homomorphic public-key cryptography.

	\item \underline{Bootle16 \cite{2016:eurocrypt:efficient-zk-args-for-arithmetic}:} 
	Compiler for converting an ILC proof into a many-round succinct proof under the discrete-log assumption. 
	Generating and verifying the proof requires a number of public-key operations that grows linearly with the size of the circuit recognizing the NP relation in question.
	\end{enumerate} 
	
		\vspace{1em}
	Note: In addition to the crypto compilers described above, there are information-theoretic compilers that convert between different types of information-theoretic objects.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\paragraph{iii) Compilers: Information-theoretic}
\subsection{Compilers: Information-theoretic}
	
	\begin{enumerate}[label=\alph*.]
  
	\item \underline{MPC-in-the-Head (IKOS \cite{2007:stoc:ZK-from-SMPC}, ZKboo \cite{2016:Sec:ZKBoo}, Ligero \cite{2017:ccs:ligero}):} 
	Compiles secure multi-party computation protocols into either (zero-knowledge) PCPs or IOPs.
  
	\item \underline{BCIOP \cite{2013:tcc:snargs-via-LIPs}:} 
	Compiles quadratic arithmetic programs (QAPs) or quadratic span programs (QSPs) into linear PCPs such that resulting linear PCP has a degree-two decision predicate. 
	The BCIOP paper also gives a compiler for converting linear PCP into 1-round LIP/ILC and adding zero-knowledge to linear PCP.
  
	\item \underline{Bootle17 \cite{2017:asiacrypt:linear-time-zkps-for-arithmetic}:} 
	Compiles a proof in the ILC model into an IOP.
	They also give an example instantiation of the ILC proof that yields an IOP proof system with square-root complexity.
	
	\end{enumerate}



\paragraph{List of references:}\pdfbookmark[1]{List of references}{pdfbkm:security:list-refs}
\cite{2013:tcc:snargs-via-LIPs},
\cite{2016:tcc:IOPs},
\cite{2017:eurocrypt:lattice-based-snargs},
\cite{2016:eurocrypt:efficient-zk-args-for-arithmetic},
\cite{2017:asiacrypt:linear-time-zkps-for-arithmetic},
\cite{2018:asiacrypt:arya-nearly-lineat-time-zkps-for-correct},
\cite{1998:crypto:zkps-for-finite-field-arithmetic},
\cite{2013:QSPs-and-succinct-NIZKs-without-PCPs},
\cite{2015:JACM:delegating-computation-interactive-proofs-for-muggles},
\cite{2010:asiacrypt:short-NIZKPs},
\cite{2018:SP:Doubly-efficient-zkSNARKs-without-trusted-setup},
\cite{2007:stoc:ZK-from-SMPC},
\cite{2012:tcc:On-Efficient-ZK-PCPs},
\cite{1995:crypto:Improved-Efficient-Arguments},
\cite{2008:icalp:interactive-PCP},
\cite{2017:ccs:ligero},
\cite{2000:SIAM:Computationally-Sound-Proofs},
\cite{2016:stoc:Constant-round-Interactive-Proofs-for-Delegating-Computation},
\cite{2018:SP:vRAM},
\cite{2017:SP:vSQL},
\cite{2016:Sec:ZKBoo}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\section{References:}
%\label{security:references}

%%%%%	\begin{itemize}
%%%%%    \item{} [BCIOP] Bitansky, N., Chiesa, A., Ishai, Y., Ostrovsky, R. \& Paneth, O. "Succinct non-interactive arguments via linear interactive proofs." TCC (2013).
%%%%%    \item{} [BCS16] Ben-Sasson, E., Chiesa, A., \& Spooner, N. "Interactive oracle proofs." TCC (2016).
%%%%%    \item{} [BISW17] Boneh, D., Ishai, Y., Sahai, A., \& Wu, D. J. “Lattice-based snargs and their application to more efficient obfuscation.” Eurocrypt (2017).
%%%%%    \item{} [Bootle16] Bootle, J., Cerulli, A., Chaidos, P., Groth, J., \& Petit, C. “Efficient zero-knowledge arguments for arithmetic circuits in the discrete log setting.” Eurocrypt (2016).
%%%%%    \item{} [Bootle17] Bootle, J., Cerulli, A., Ghadafi, E., Groth, J., Hajiabadi, M., \& Jakobsen, S. K. “Linear-time zero-knowledge proofs for arithmetic circuit satisfiability.” Asiacrypt (2017).
%%%%%    \item{} [Bootle18] Bootle, J., Cerulli, A., Groth, J., Jakobsen, S., \& Maller, M. “Nearly Linear-Time Zero-Knowledge Proofs for Correct Program Execution” ePrint 2018/380 (2018).
%%%%%    \item{} [Cramer-Damgård] Cramer, R., \& Damgård, I. “Zero-knowledge proofs for finite field arithmetic, or: Can zero-knowledge be for free?.” CRYPTO (1998).
%%%%%    \item{} [GGPR] Gennaro, R., Gentry, C., Parno, B., \& Raykova, M. “Quadratic span programs and succinct NIZKs without PCPs.” Eurocrypt (2013).
%%%%%    \item{} [GKW] Goldwasser, S., Kalai, Y. T., \& Rothblum, G. N. “Delegating computation: interactive proofs for muggles.” STOC (2008).
%%%%%    \item{} [Groth10] Groth, J.”Short Non-interactive Zero-Knowledge Proofs.” ASIACRYPT (2010)
%%%%%    \item{} [Hyrax] Wahby, R. S., Tzialla, I., Thaler, J., \& Walfish, M. “Doubly-efficient zkSNARKs without trusted setup.” IEEE Security and Privacy (2018).
%%%%%    \item{} [IKOS] Ishai, Y., Kushilevitz, E., Ostrovsky, R., \& Sahai, A. “Zero-knowledge from secure multiparty computation.” STOC (2007).
%%%%%    \item{} [IMS] Ishai, Y., Mahmoody, M., \& Sahai, A. “On Efficient Zero-Knowledge PCPs.” TCC (2012)
%%%%%    \item{} [Kilian] Kilian, J. “Improved efficient arguments.” CRYPTO (1995).
%%%%%    \item{} [KR08] Kalai, Y. T., \& Raz, R. “Interactive PCP.” ICALP (2008).
%%%%%    \item{} [Ligero] Ames, S., Hazay, C., Ishai, Y., \& Venkitasubramaniam, M. “Ligero: Lightweight sublinear arguments without a trusted setup.” CCS (2017).
%%%%%    \item{} [Micali] Micali, S. "Computationally sound proofs." SIAM Journal on Computing (2000).
%%%%%    \item{} [RRR] Reingold, O., Rothblum, G. N., \& Rothblum, R. D. “Constant-round interactive proofs for delegating computation.” STOC (2016).
%%%%%    \item{} [vRAM] Zhang, Y., Katz, J., Papadopoulos, D., \& Papamanthou, C. “vRAM: Faster Verifiable RAM With Program-Independent Preprocessing.” IEEE Security and Privacy (2018).
%%%%%    \item{} [vSQL] Zhang, Y., Genkin, D., Katz, J., Papadopoulos, D., \& Papamanthou, C. “vSQL: Verifying arbitrary SQL queries over dynamic outsourced databases.” IEEE Security and Privacy (2017).
%%%%%	\end{itemize}



